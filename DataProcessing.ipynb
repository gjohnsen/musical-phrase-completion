{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loose inspiration from: https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "\n",
    "\n",
    "# From a corpus of midi files, generate tokens for a sequence model\n",
    "\n",
    "\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from music21.midi import MidiException\n",
    "from random import shuffle\n",
    "import time\n",
    "import os\n",
    "import signal\n",
    "import sys\n",
    "import warnings\n",
    "import glob\n",
    "\n",
    "\n",
    "# Instruments to look for\n",
    "instr = (instrument.Piano, instrument.StringInstrument, instrument.Harpsichord)\n",
    "\n",
    "# Ignore warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "# Custom exception class for time-out\n",
    "class TimeoutException(Exception):   \n",
    "    pass\n",
    "\n",
    "# Custom signal handler\n",
    "def timeout_handler(signum, frame):   \n",
    "    raise TimeoutException\n",
    "\n",
    "# Change the behavior of SIGALRM\n",
    "signal.signal(signal.SIGALRM, timeout_handler)\n",
    "\n",
    "\n",
    "# Tokenize midis in source_dir for training sequence model\n",
    "def tokenize_midis(source_dir, dest_file, timeout=30, monophonic=False, rests=False, durations=False, \n",
    "                   instr = (instrument.Piano, instrument.StringInstrument, instrument.Harpsichord)):\n",
    "    \n",
    "    # Iterate over midis in directory\n",
    "    midi_list = glob.glob(source_dir + '/**/*.mid', recursive=True)\n",
    "    shuffle(midi_list)\n",
    "    \n",
    "    # Create a log of the file ordering\n",
    "    with open(('.').join(dest_file.split('.')[:-1])+'_log.txt', 'w') as outlog:\n",
    "        for file in midi_list:\n",
    "            outlog.write(file + \"\\n\")\n",
    "    \n",
    "    total = len(midi_list)\n",
    "    i = 1\n",
    "    outfile = open(dest_file, 'w')\n",
    "    \n",
    "    for file in midi_list:\n",
    "        tokens = []\n",
    "        \n",
    "        # Set time-out alarm (seconds) in case transposing is taking too long\n",
    "        signal.alarm(timeout)\n",
    "        \n",
    "        # Try to parse the file\n",
    "        try:\n",
    "            s1 = converter.parse(file)\n",
    "            notes_to_parse = None\n",
    "            \n",
    "            # If flat file\n",
    "            if len(s1.parts) == 1:\n",
    "                if monophonic:\n",
    "                    notes_to_parse = s1.flat.notes\n",
    "                else:\n",
    "                    notes_to_parse = s1.flat.notes.chordify()\n",
    "            \n",
    "            # If file has parts matching desired instruments\n",
    "            elif any(isinstance(part.getInstrument(), instr) for part in s1.parts):\n",
    "                for part in s1.parts:\n",
    "                    if not isinstance(part.getInstrument(), instr):\n",
    "                        s1.remove(part)\n",
    "                if monophonic:\n",
    "                    notes_to_parse = s1.parts[0]\n",
    "                else:\n",
    "                    notes_to_parse = s1.parts.chordify()\n",
    "                \n",
    "            # If no matching parts, try first one\n",
    "            else:\n",
    "                if monophonic:\n",
    "                    notes_to_parse = s1.parts[0]\n",
    "                else:\n",
    "                    notes_to_parse = s1.parts[0].chordify()\n",
    "                \n",
    "            # Perform tokenization\n",
    "            for element in notes_to_parse:\n",
    "                if isinstance(element, note.Note):\n",
    "                    if durations:\n",
    "                        tokens.append(str(element.pitch)+'.'+str(element.duration.type))\n",
    "                    else:\n",
    "                        tokens.append(str(element.pitch))\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    if monophonic:\n",
    "                        if durations:\n",
    "                            tokens.append(element.root().name + str(element.root().octave) + '.' + str(element.duration.type))\n",
    "                        else:\n",
    "                            tokens.append(element.root().name + str(element.root().octave))\n",
    "                    else:\n",
    "                        if durations:\n",
    "                            tokens.append('.'.join((pitch.name + str(pitch.octave)) for pitch in element.pitches)+'.'+str(element.duration.type))\n",
    "                        else:\n",
    "                            tokens.append('.'.join((pitch.name + str(pitch.octave)) for pitch in element.pitches))\n",
    "                elif isinstance(element, note.Rest):\n",
    "                    if rests:\n",
    "                        tokens.append('rest')\n",
    "        \n",
    "        # Tokenizing took too long\n",
    "        except TimeoutException:\n",
    "            print(\"Time-out tokenizing file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "        \n",
    "        # Tokenizing encountered an error\n",
    "        except (MidiException, IndexError, TypeError):\n",
    "            print(\"Exception tokenizing file\", i, \"out of\", total, \"(\", file, \")\")\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            signal.alarm(0)\n",
    "            print(\"Tokenized file\", i, \"out of\", total)\n",
    "            \n",
    "        finally:\n",
    "            i += 1\n",
    "        \n",
    "        outfile.write(\" \".join(tokens)+\"\\n\")\n",
    "        \n",
    "    outfile.close()\n",
    "    print('Tokens written to %s' % dest_file)\n",
    "    print('Vocabulary size is %i' % len(set(w for w in open(dest_file).read().split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized file 1 out of 40\n",
      "Tokenized file 2 out of 40\n",
      "Tokenized file 3 out of 40\n",
      "Tokenized file 4 out of 40\n",
      "Tokenized file 5 out of 40\n",
      "Tokenized file 6 out of 40\n",
      "Tokenized file 7 out of 40\n",
      "Tokenized file 8 out of 40\n",
      "Tokenized file 9 out of 40\n",
      "Tokenized file 10 out of 40\n",
      "Tokenized file 11 out of 40\n",
      "Tokenized file 12 out of 40\n",
      "Tokenized file 13 out of 40\n",
      "Tokenized file 14 out of 40\n",
      "Tokenized file 15 out of 40\n",
      "Tokenized file 16 out of 40\n",
      "Tokenized file 17 out of 40\n",
      "Tokenized file 18 out of 40\n",
      "Tokenized file 19 out of 40\n",
      "Tokenized file 20 out of 40\n",
      "Tokenized file 21 out of 40\n",
      "Tokenized file 22 out of 40\n",
      "Tokenized file 23 out of 40\n",
      "Tokenized file 24 out of 40\n",
      "Tokenized file 25 out of 40\n",
      "Tokenized file 26 out of 40\n",
      "Tokenized file 27 out of 40\n",
      "Tokenized file 28 out of 40\n",
      "Tokenized file 29 out of 40\n",
      "Tokenized file 30 out of 40\n",
      "Tokenized file 31 out of 40\n",
      "Tokenized file 32 out of 40\n",
      "Tokenized file 33 out of 40\n",
      "Tokenized file 34 out of 40\n",
      "Tokenized file 35 out of 40\n",
      "Tokenized file 36 out of 40\n",
      "Tokenized file 37 out of 40\n",
      "Tokenized file 38 out of 40\n",
      "Tokenized file 39 out of 40\n",
      "Tokenized file 40 out of 40\n",
      "Tokens written to ./tokenized/vivaldi_mono.txt\n",
      "Vocabulary size is 50\n",
      "Tokenized file 1 out of 40\n",
      "Tokenized file 2 out of 40\n",
      "Tokenized file 3 out of 40\n",
      "Tokenized file 4 out of 40\n",
      "Tokenized file 5 out of 40\n",
      "Tokenized file 6 out of 40\n",
      "Tokenized file 7 out of 40\n",
      "Tokenized file 8 out of 40\n",
      "Tokenized file 9 out of 40\n",
      "Tokenized file 10 out of 40\n",
      "Tokenized file 11 out of 40\n",
      "Tokenized file 12 out of 40\n",
      "Tokenized file 13 out of 40\n",
      "Tokenized file 14 out of 40\n",
      "Tokenized file 15 out of 40\n",
      "Tokenized file 16 out of 40\n",
      "Tokenized file 17 out of 40\n",
      "Tokenized file 18 out of 40\n",
      "Tokenized file 19 out of 40\n",
      "Tokenized file 20 out of 40\n",
      "Tokenized file 21 out of 40\n",
      "Tokenized file 22 out of 40\n",
      "Tokenized file 23 out of 40\n",
      "Tokenized file 24 out of 40\n",
      "Tokenized file 25 out of 40\n",
      "Tokenized file 26 out of 40\n",
      "Tokenized file 27 out of 40\n",
      "Tokenized file 28 out of 40\n",
      "Tokenized file 29 out of 40\n",
      "Tokenized file 30 out of 40\n",
      "Tokenized file 31 out of 40\n",
      "Tokenized file 32 out of 40\n",
      "Tokenized file 33 out of 40\n",
      "Tokenized file 34 out of 40\n",
      "Tokenized file 35 out of 40\n",
      "Tokenized file 36 out of 40\n",
      "Tokenized file 37 out of 40\n",
      "Tokenized file 38 out of 40\n",
      "Tokenized file 39 out of 40\n",
      "Tokenized file 40 out of 40\n",
      "Tokens written to ./tokenized/vivaldi_poly_dur.txt\n",
      "Vocabulary size is 9037\n",
      "Tokenizations complete!\n"
     ]
    }
   ],
   "source": [
    "tokenize_midis('./classical_midis/vivaldi/', './tokenized/vivaldi_mono.txt', monophonic=True)\n",
    "tokenize_midis('./classical_midis/vivaldi/', './tokenized/vivaldi_poly_dur.txt', durations=True)\n",
    "print('Tokenizations complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
